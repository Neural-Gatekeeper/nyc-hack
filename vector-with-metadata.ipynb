from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

# Sample documents with metadata
documents_with_metadata = [
    {'id': 1, 'text': "This is the first document.", 'category': 'A'},
    {'id': 2, 'text': "This document is the second document.", 'category': 'B'},
    {'id': 3, 'text': "And this is the third one.", 'category': 'B'},
    {'id': 4, 'text': "Is this the first document?", 'category': 'C'},
]

# Sample user information with categories
user_info = {'user_id': 123, 'category': 'B'}

# Extract text and metadata from documents
texts = [doc['text'] for doc in documents_with_metadata]
metadata = [{'id': doc['id'], 'category': doc['category']} for doc in documents_with_metadata]

# Create TF-IDF vectorizer with metadata
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(texts)

# Get the vector representation of each document
vector_store = tfidf_matrix.toarray()

# Sample query with metadata
query = "This is the second document."

    # Transform the query into TF-IDF vector with metadata
query_vector = vectorizer.transform([query]).toarray()

    # Calculate cosine similarity between the query vector and document vectors
similarities = cosine_similarity(query_vector, vector_store)

    # Get the indices of the top five most similar documents
top_indices = np.argsort(similarities[0])[-5:][::-1]
print(top_indices)

    # Print the top five most similar documents and their metadata
print("Query:", query)
print("Top five most similar documents:")
for index in top_indices:
  documet_info = documents_with_metadata[index]
  if user_info['category'] == documet_info['category']:
    # User is authorized to access documents of this category
    print(f"Document {index}: {documet_info}")
  else:
    print("Unauthorized access. User does not have the required category.")
